# RNN for Generating Music
This project uses a Recurrent Neural Network (RNN) made with Python, TensorFlow, and data visualization libraries to generate music. The model is trained on a dataset of MIDI files, which it parses and analyzes each note of. Each note has unique values of pitch, step, and duration, which the model then attempts to predict. The goal of this project is to demonstrate how basic machine learning techniques can be applied to the creative process. 

I used Python in Visual Studio Code to help me write this, in addition to a TensorFlow tutorial. You'll likely have to download some of the libraries used, especially including pretty_midi and Pyfluidsynth. Please read "Music RNN Explained" 1 and 2, which explain what each chunk of code does!

## Table of Contents
- [Dataset](dataset)
- [Dependencies](dependencies)
- Explanation
    - [Part 1](Music-RNN-Explained-1.pdf)
    - [Part 2](docs/Music-RNN-Explained-2.pdf)
- [Project Structure](music_rnn.ipynb)
- [Output](output)
- [License](LICENSE)
